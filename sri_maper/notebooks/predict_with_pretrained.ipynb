{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to load and use a ResNet pretrained fror MVT Lead-Zinc Deposits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "from sri_maper.src.models.cma_module import CMALitModule\n",
    "import sys\n",
    "if sys.version_info < (3, 9):\n",
    "    from importlib_resources import files\n",
    "else:\n",
    "    from importlib.resources import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:269: UserWarning: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "ResNet                                        [1, 1]                    --\n",
       "├─FeatureListNet: 1-1                         [1, 512, 2, 2]            --\n",
       "│    └─Conv2d: 2-1                            [1, 64, 17, 17]           228,928\n",
       "│    └─BatchNorm2d: 2-2                       [1, 64, 17, 17]           128\n",
       "│    └─ReLU: 2-3                              [1, 64, 17, 17]           --\n",
       "│    └─MaxPool2d: 2-4                         [1, 64, 9, 9]             --\n",
       "│    └─Sequential: 2-5                        [1, 64, 9, 9]             --\n",
       "│    │    └─BasicBlock: 3-1                   [1, 64, 9, 9]             73,984\n",
       "│    │    └─BasicBlock: 3-2                   [1, 64, 9, 9]             73,984\n",
       "│    └─Sequential: 2-6                        [1, 128, 5, 5]            --\n",
       "│    │    └─BasicBlock: 3-3                   [1, 128, 5, 5]            230,144\n",
       "│    │    └─BasicBlock: 3-4                   [1, 128, 5, 5]            295,424\n",
       "│    └─Sequential: 2-7                        [1, 256, 3, 3]            --\n",
       "│    │    └─BasicBlock: 3-5                   [1, 256, 3, 3]            919,040\n",
       "│    │    └─BasicBlock: 3-6                   [1, 256, 3, 3]            1,180,672\n",
       "│    └─Sequential: 2-8                        [1, 512, 2, 2]            --\n",
       "│    │    └─BasicBlock: 3-7                   [1, 512, 2, 2]            3,673,088\n",
       "│    │    └─BasicBlock: 3-8                   [1, 512, 2, 2]            4,720,640\n",
       "├─Sequential: 1-2                             [1, 1]                    --\n",
       "│    └─AdaptiveAvgPool2d: 2-9                 [1, 512, 1, 1]            --\n",
       "│    └─Flatten: 2-10                          [1, 512]                  --\n",
       "│    └─Dropout: 2-11                          [1, 512]                  --\n",
       "│    └─Linear: 2-12                           [1, 1]                    513\n",
       "===============================================================================================\n",
       "Total params: 11,396,545\n",
       "Trainable params: 11,396,545\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 143.65\n",
       "===============================================================================================\n",
       "Input size (MB): 0.32\n",
       "Forward/backward pass size (MB): 1.23\n",
       "Params size (MB): 45.59\n",
       "Estimated Total Size (MB): 47.14\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loads the pretrained checkpoint\n",
    "ckpt_path = str(files(\"sri_maper.ckpts\") / \"epoch_007.ckpt\")\n",
    "model = CMALitModule.load_from_checkpoint(ckpt_path)\n",
    "# prints a model summary\n",
    "summary(model.net, input_size=(1,73,33,33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates random sample data\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_patch = torch.rand((2,73,33,33), device=device)\n",
    "label = torch.randint(low=0, high=1, size=(2,), device=device)\n",
    "batch_idx = 0\n",
    "locs = torch.tensor([[-93.19,-93],[32.44,32.44]], device=device) # [list of longs, list of lats]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the CMA module in various ways by calling its methods. \n",
    "\n",
    "Please see the documentation within the methods for details. \n",
    "\n",
    "Below we provide examples of calling each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits:tensor([[-5.4023],\n",
      "        [-5.6066]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# prints logits\n",
    "logits = model.forward(input_patch)\n",
    "print(f\"Logits:{model.forward(input_patch)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:0.16410422325134277\n",
      "Pred:tensor([[0.],\n",
      "        [0.]], device='cuda:0', dtype=torch.float16)\n",
      "Target:tensor([0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# prints loss, predictions, and labels\n",
    "loss, pred, target = model.model_step((input_patch, label))\n",
    "print(f\"Loss:{loss}\")\n",
    "print(f\"Pred:{pred}\")\n",
    "print(f\"Target:{target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long, Lat: tensor([-93.1900,  32.4400], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Likelihood, Uncertainty: tensor([0.0182, 0.0440], device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Feature attributions: tensor([ 3.0759e-05, -3.7590e-05, -7.3854e-07,  2.3355e-05, -1.2856e-05,\n",
      "         2.0724e-06, -1.7814e-05,  1.0744e-05, -1.1759e-05, -1.5473e-05,\n",
      "        -2.2104e-05, -9.2097e-06, -1.0176e-05, -1.9268e-05,  1.9260e-06,\n",
      "        -4.1062e-06,  1.8495e-05, -1.6228e-05, -4.6928e-06, -3.3547e-05,\n",
      "        -3.6940e-05, -2.3548e-05, -6.8299e-05, -1.0001e-05, -1.5050e-05,\n",
      "        -2.2456e-05, -8.4889e-06,  3.4970e-06, -2.6028e-05, -3.3174e-05,\n",
      "        -1.2171e-05, -3.2828e-05, -1.1060e-05, -6.8202e-05, -3.2495e-05,\n",
      "        -1.9297e-06, -7.2174e-06, -1.7573e-05,  8.1906e-06,  1.7460e-05,\n",
      "        -6.1063e-06, -5.0287e-05, -6.7967e-05,  6.5304e-06, -6.4605e-05,\n",
      "        -1.3587e-05, -5.1910e-05, -2.9643e-06, -5.9390e-06, -2.4791e-05,\n",
      "        -8.5277e-06, -4.7653e-05, -4.2457e-05, -4.1012e-05, -2.4489e-05,\n",
      "        -4.6339e-05, -2.9610e-05, -2.7773e-05,  5.4550e-06, -6.7917e-05,\n",
      "         1.2467e-05, -7.6582e-05, -4.3930e-06, -2.9371e-05, -1.1145e-05,\n",
      "         2.1678e-07, -7.1707e-05, -1.8184e-05, -5.7532e-05, -4.1694e-05,\n",
      "        -1.4393e-05, -2.0022e-05, -5.8538e-05], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# prints likelihood, uncertainty, and feature attribution\n",
    "output_tensor = model.predict_step((input_patch, label, locs[0], locs[1]), batch_idx)\n",
    "print(f\"Long, Lat: {output_tensor[0,:2]}\")\n",
    "print(f\"Likelihood, Uncertainty: {output_tensor[0,2:4]}\")\n",
    "print(f\"Feature attributions: {output_tensor[0,4:]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
