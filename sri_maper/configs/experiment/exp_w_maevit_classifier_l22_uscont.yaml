# @package _global_

defaults:
  - override /preprocess: tungsten-skarn-natl.yaml
  - override /model: maevit_classifier.yaml
  - override /trainer: ddp
  - override /callbacks: default.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["w", "cUS", "mae-vit-classifier-cls"]
task_name: "cmta3-classifier-maevit"

seed: 1234
extract_attributions: true

data:
  tif_dir: ${paths.data_dir}/H3/Tungsten-Skarn
  likely_neg_range: [0.2,0.4]

model:
  optimizer:
    _target_: torch.optim.AdamW
    lr: 1e-4
    weight_decay: 1e-3
  net:
    _target_: sri_maper.src.models.mae_vit_classifier.CLSClassifer
    backbone_ckpt: "logs/cmta3-pretrain-maevit/runs/2024-03-14_20-01-15/checkpoints/ssim_0.878.ckpt"
    backbone_net:
      _target_: sri_maper.src.models.mae_vit.MAE_ViT
      image_size: 33
      patch_size: 3
      input_dim: 77
      enc_dim: 256
      encoder_layer: 6
      encoder_head: 8
      dec_dim: 128
      output_dim: 77
      decoder_layer: 2
      decoder_head: 4
      mask_ratio: 0.75
    freeze_backbone: false
    dropout_rate: 0.5
  compile: false
  gain: 1.0
  mc_samples: 100
  smoothing: 0.2
  extract_attributions: ${extract_attributions}
  
trainer:
  min_epochs: 1
  max_epochs: 100
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  val_check_interval: 0.5
  # gradient_clip_val: 1.0

logger:
  wandb:
    name: "exp_w_maevit_classifier_l22_uscont"

callbacks:
  model_checkpoint:
    monitor: val/auprc
  early_stopping:
    monitor: val/auprc_best